---
title: "Unpaired Variant Consensus Workflow"
author: "Amy Paguirigan"
date: "6/3/2019"
output: html_document
editor_options: 
  chunk_output_type: console
---
# Install Required Packages

## For Local Use
```{r}
devtools::install_github('FredHutch/tgR')
devtools::install_github('FredHutch/fh.wdlR')
```

# Load Packages
```{r}
library(tidyverse); library(tgR); library(fh.wdlR)
```

# Set Credentials (run one line)
```{r}
setCreds(tokenSet = "file", path = "~/github/cred/paguirigan.R") #laptop
```

# Pull S3 Inventory and Annotate
```{r}
tags <- listS3Objects(bucket = "fh-pi-paguirigan-a")
annotations <- redcapPull(domain = "all", DAG = "paguirigana", harmonizedOnly = TRUE)
monsterMash <- dplyr::left_join(tags, annotations)
```

# Filter Inventory for Workflow Input Data
In this workflow, the input data must be unmapped bams with quality control checks.  Also, to run the workflow you'll need the bed file for the dataset up in S3.
```{r}
subData <- monsterMash %>% filter(workflowID == "fastq-unmappedbam") %>% Filter(function(x)!all(is.na(x)), .) %>% unique()

unpaired <- subData %>% select(molecular_id, omics_sample_name, key, seq_libtype)
unpaired$bamLocation <- paste0("s3://fh-pi-paguirigan-a/", unpaired$key)

unpaired$bedLocation <- ifelse(unpaired$seq_libtype == "one", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/TruSight-One-Illumina/TruSight_One_v1.1-liftover-hg38.bed",
                               ifelse(unpaired$seq_libtype == "tsm", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/TruSight-Myeloid-Illumina/trusight-myeloid-amplicon-v4-track_interval-liftOver-hg38.bed",
                                      ifelse(unpaired$seq_libtype == "washu", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/WASHU-AML/washU_intervals-remapped-hg38.bed",
                                             ifelse(unpaired$seq_libtype == "agssex6", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/AgilentSureSelectv6-Exome/S07604514_Covered-remapped-hg38.bed",
                                                    ifelse(unpaired$seq_libtype == "agssex5", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/AgilentSureSelectv5-Exome/S04380110_Covered-remapped-hg38.bed",
                                                           ifelse(unpaired$seq_libtype == "tapestriAMLPanel", "s3://fh-ctr-public-reference-data/reagent_specific_data/sequencing_panel_bed/MissionBio-AMLPanel/2019-02-13-MissionBioAML.bed", ""))))))
preselect <- unpaired
preselect <- unpaired %>% filter(!is.na(bedLocation)) %>% filter(seq_libtype == "one")
manifest <- preselect %>% select(omics_sample_name, bamLocation, bedLocation, molecular_id)
```


# Prefilter manifest if needed
```{r}
manifest <- manifest[5:9,]
```

# Name and Ship Batch File
```{r}
batchFileName <- paste0("cromwell-manifests/",format(Sys.Date(), "%Y-%m-%d-"), "newdockerContainers.tsv")
paste0("s3://fh-pi-paguirigan-a-genomicsrepo/", batchFileName)
s3write_using(manifest,
              FUN = write.table, quote = F, row.names = F, sep = "\t",
              object = batchFileName,
              bucket = "fh-pi-paguirigan-a-genomicsrepo")
thisManifest <- "cromwell-manifests/2019-06-06-newdockerContainers.tsv"
```

```{r}
cromwellCreate(FredHutchId = "apaguiri", port = "1981",
        pathToServerLogs =
          "/fh/fast/paguirigan_a/user/apaguiri/cromwell/tgr/server-logs/frank-%A.txt",
        pathToScript = 
          "/fh/fast/paguirigan_a/user/apaguiri/cromwell/tgr/beAllEndAll.sh",
        pathToParams = 
          "/fh/fast/paguirigan_a/user/apaguiri/cromwell/tgr/allTheParams.sh")

setCromwellURL(FredHutchId = "username", jobId = "45731945", port = "1981")
Sys.setenv("CROMWELLURL" = "http://,,,,,,,")
```



# Submit Job to Cromwell
```{r}

thisJob <- cromwellSubmitBatch(WDL = "AWS/variantCalling-AWS-workflow.wdl",
                    Params = "AWS/variantCalling-AWS-parameters.json",
                    Batch = "AWS/variantCalling-AWS-batchofOne.json",
                    Options = "AWS/workflow-options.json",
                    Labels = data.frame("workflowType" = "awsnewqueue"))


womtoolValidate(WDL = "variantCalling.wdl",allInputs = "variantCalling-aws-parameters.json")

thisJob <- cromwellSubmitBatch(WDL = "variantCalling.wdl",
                    Params = "variantCalling-aws-parameters.json",
                    Batch = "variantCalling-aws-batch.json",
                    Options = "aws-options.json",
                    Labels = data.frame("workflowType" = "awsnewqueue"))
thisOne <- thisJob$id; thisOne

womtoolValidate(WDL = "variantCalling.wdl",allInputs = "variantCalling-local-parameters.json")

thisJob <- cromwellSubmitBatch(WDL = "variantCalling.wdl",
                    Params = "variantCalling-local-parameters.json",
                    Batch = "variantCalling-local-batch.json",
                    Options = "local-options.json",
                    Labels = data.frame("workflowType" = "newonbeagle"))
thisOne <- thisJob$id; thisOne
```


# Monitor Running Jobs
```{r}
jobs <- cromwellJobs()
thisOne <- jobs$workflow_id[1]; thisOne
thisOne <- jobs$workflow_id[2]

w <- cromwellWorkflow(thisOne); w$status
c <- cromwellCall(thisOne); c %>% group_by(executionStatus, callName) %>% summarize(status = n())
ca <- cromwellCache(thisOne); ca %>% group_by(callCaching.hit, callName) %>% summarize(hits = n())
butWhy <- left_join(cromwellCall(thisOne) %>% mutate_all(as.character), 
                    cromwellCache(thisOne) %>% mutate_all(as.character)); butWhy %>% group_by(callName, executionStatus, callCaching.hit) %>% summarize(hits = n()) %>% arrange(desc(executionStatus))
f <- cromwellFailures(thisOne); f
#abort <- cromwellAbort(thisOne) # Careful with this
WTF <- cromwellGlob(thisOne); WTF[["failures"]]
```



# Output Processing
```{r}
out <- cromwellOutputs(thisOne) 
batchFile <- s3read_using(FUN = read.delim, stringsAsFactors = F,
                           object = thisManifest,
                           bucket = "fh-pi-paguirigan-a-genomicsrepo")
batchFile$shardIndex <- as.character(seq(from = 0, to = nrow(batchFile)-1, by = 1))
annotatedOutputs <- inner_join(batchFile, out, by = c("shardIndex")) # if no molecular_id
copyNTag <- annotatedOutputs %>%
  select(molecular_id, workflowOutputType, s3URL, s3Prefix, workflow_id, workflowName, s3Bucket) %>%
  rename("workflowID" = "workflow_id")
copyNTag$s3DestinationPrefix <- gsub( "cromwell-output/", "tg/TGR-Analyses/",gsub("call-[^/]*/", "", copyNTag$s3Prefix))
copyNTag$s3DestinationBucket <- "fh-pi-paguirigan-a"
copyNTag$stage <- "processed"
copyNTag[10,]
```

# Copy Outputs and Tag
```{r}
colnames(copyNTag)
#Only keep columns you need or want to use as tags
readyToRoll <- copyNTag %>% select(s3Prefix, s3Bucket, s3DestinationPrefix, s3DestinationBucket, molecular_id, stage, workflowID, workflowName); colnames(readyToRoll)

QuitePossibly <- prep_s3_copy_and_tag(readyToRoll); QuitePossibly[1]

future::plan(strategy = multiprocess)
output <- furrr::future_map(QuitePossibly, function(x) {
  s3_copy_and_tag(fromBucket = x$s3Bucket,
                  fromPrefix = x$s3Prefix,
                  toBucket = x$s3DestinationBucket,
                  toPrefix = x$s3DestinationPrefix,
                  tagList = x$tagSet)
  print(x$s3DestinationPrefix)
  return(y)
})
```

# For Large file copies you have to use the command line
Change WD to directory on Fast where the output-copy-and-tag.sh script (and arrayjob.sh) are saved for this project.  
```{r}
write.table(readyToRoll, file = "2019-06-28-breedbate-cleanCalling-HALO-goodQC.txt",
            sep = " ", na = "", row.names = F, col.names = F, quote = F)
```


```{bash}
ssh apaguiri@rhino
module load awscli
sbatch --job-name 2019-06-18-zoanthropy-LILACtest-copy.txt arrayjob.sh
bash monitorjobs.sh <jobID>
```
## FINAL NOTE:  copy the WDL used and any parameter files to S3 into the final data directory too!!!!




# Memory testing snippets
```{r}
thisID <- "a7bb74fd-e602-4217-88d1-b6917796358c"
withMultipler2 <- "e4502446-444b-4d03-9ee0-36878f10ba4c"
withMultiplierHalf <- "32e14d98-d0ca-46f4-94f1-d265c174889e"

adjusted1 <- "c87a7ef3-af25-4588-bbca-002320a19340"
adjusted2 <- "522b1a72-e19b-4e21-a00d-935318722f59"
magic <- "1ec38d0b-afc4-4cd5-90f1-f015395d6e36"

oneX <- cromwellCall(adjusted1)
durationOneX <- oneX %>% select(callName, shardIndex, jobDuration, memory) %>%
  rename("oneXDuration" = "jobDuration", "oneXmemory" = "memory")

twoX <- cromwellCall(adjusted2)
durationTwoX <- twoX %>% select(callName, shardIndex, jobDuration, memory) %>%
  rename("twoXDuration" = "jobDuration", "twoXmemory" = "memory")
comparisonTwo <- left_join(durationOneX, durationTwoX, by = c("callName", "shardIndex")) %>%
  mutate(twoXImprovement = oneXDuration - twoXDuration)

overall <- full_join(durationTwoX, durationOneX)
overall <- overall %>% mutate(twoImp = oneXDuration-twoXDuration)

overall %>% group_by(callName) %>% summarise(meanTwo = mean(twoImp, na.rm = T))
```



